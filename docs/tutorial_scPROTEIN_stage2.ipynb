{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "5ff430ce",
   "metadata": {},
   "source": [
    "## Running scPROTEIN stage2 on SCoPE2_Specht dataset\n",
    "\n",
    "In this tutorial, we show how to run scPROTEIN using protein-level data as input and generate the cell embedding."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "b574d277",
   "metadata": {},
   "outputs": [],
   "source": [
    "import argparse\n",
    "import random\n",
    "import numpy as np \n",
    "import scipy.sparse as sp\n",
    "import os\n",
    "from sklearn import metrics\n",
    "from sklearn.metrics import silhouette_score,adjusted_rand_score,normalized_mutual_info_score\n",
    "from sklearn.metrics.cluster import contingency_matrix\n",
    "from scprotein import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "8b02a48d",
   "metadata": {},
   "outputs": [],
   "source": [
    "os.environ[\"PYTORCH_CUDA_ALLOC_CONF\"] = \"max_split_size_mb:128\"\n",
    "\n",
    "parser = argparse.ArgumentParser()\n",
    "parser.add_argument(\"--stage1\", type=bool, default=True, help='if scPROTEIN starts from stage1')\n",
    "parser.add_argument(\"--learning_rate\", type=float, default=1e-3, help='learning rate')\n",
    "parser.add_argument(\"--num_hidden\", type=int, default=400, help='hidden dimension') \n",
    "parser.add_argument(\"--num_proj_hidden\", type=int, default=256, help='dimension of projection head')\n",
    "parser.add_argument(\"--activation\", type=str, default='prelu', help='activation function') \n",
    "parser.add_argument(\"--num_layers\", type=int, default=2, help='num of GCN layers')\n",
    "parser.add_argument(\"--num_protos\", type=int, default=2, help='num of prototypes')\n",
    "parser.add_argument(\"--num_changed_edges\", type=int, default=50, help='num of added/removed edges')\n",
    "parser.add_argument(\"--topology_denoising\", type=bool, default=False, help='if scPROTEIN uses topology denoising')\n",
    "parser.add_argument(\"--drop_edge_rate_1\", type=float, default=0.2, help='dropedge rate for view1')\n",
    "parser.add_argument(\"--drop_edge_rate_2\", type=float, default=0.4, help='dropedge rate for view2')\n",
    "parser.add_argument(\"--drop_feature_rate_1\", type=float, default=0.4, help='mask_feature rate for view1')\n",
    "parser.add_argument(\"--drop_feature_rate_2\", type=float, default=0.2, help='mask_feature rate for view2')\n",
    "parser.add_argument(\"--alpha\", type=float, default=0.05, help='balance factor')\n",
    "parser.add_argument(\"--tau\", type=float, default=0.4, help='temperature coefficient')\n",
    "parser.add_argument(\"--weight_decay\", type=float, default=0.00001, help='weight_decay')\n",
    "parser.add_argument(\"--num_epochs\", type=int, default=200, help='Number of epochs.')\n",
    "parser.add_argument(\"--seed\", type=int, default=39788, help='Random seed.') \n",
    "parser.add_argument(\"--threshold\", type=float, default=0.15, help='threshold of graph construct')\n",
    "parser.add_argument(\"--feature_preprocess\", type=bool, default=True, help='feature preprocess')\n",
    "args =parser.parse_known_args()[0]   \n",
    "setup_seed(args.seed)\n",
    "activation = nn.PReLU() if args.activation == 'prelu' else F.relu\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "805a75b0",
   "metadata": {},
   "source": [
    "### Load the protein-level data from stage1 and establish the stage2 framework.\n",
    "\n",
    "\n",
    "The following functions are used for stage2 construction:\n",
    "<br/>\n",
    "\n",
    "**graph_generation(features, threshold, feature_preprocess)**\n",
    "\n",
    "**- Function:**\n",
    "\n",
    "This function constructs the cell graph based on the protein feature matrix.\n",
    "\n",
    "**- Parameters:**\n",
    "\n",
    "- `features` (array): Single-cell proteomics data matrix.\n",
    "- `threshold` (float): Threshold for graph construction.\n",
    "- `feature_preprocess` (bool): Feature preprocessing.\n",
    "\n",
    "**- Returns:**\n",
    "\n",
    "- `graph_data` (torch_geometric data object): The graph data in torch_geometric format, consisting of edges and node features.\n",
    "\n",
    "\n",
    "\n",
    "<br/>\n",
    "\n",
    "\n",
    "**Encoder(input_features, num_hidden, activation, num_layers)**\n",
    "\n",
    "**- Function:**\n",
    "\n",
    "Construct the graph encoder for embedding learning.\n",
    "\n",
    "**- Parameters:**\n",
    "\n",
    "- `input_features` (int): Dimension of the input feature matrix (usually the number of proteins).\n",
    "- `num_hidden` (int): Hidden dimension in the graph encoder.\n",
    "- `activation` (str): The type of non-linear activation function.\n",
    "- `num_layers` (int): Number of layers in the graph encoder.\n",
    "\n",
    "**- Returns:**\n",
    "\n",
    "- `encoder` (PyTorch module): The defined graph encoder module.\n",
    "\n",
    "\n",
    "<br/>\n",
    "\n",
    "\n",
    "**Model(encoder, num_hidden, num_proj_hidden, tau)**\n",
    "\n",
    "**- Function:**\n",
    "\n",
    "This function establishes the scPROTEIN *stage2* model, consisting of a graph encoder, projection head, and loss calculation.\n",
    "\n",
    "**- Parameters:**\n",
    "\n",
    "- `encoder` (PyTorch module): Defined graph encoder.\n",
    "- `num_hidden` (int): Hidden dimension in the graph encoder.\n",
    "- `num_proj_hidden` (int): Hidden dimension of the projection head.\n",
    "- `tau` (float): Temperature coefficient.\n",
    "\n",
    "**- Returns:**\n",
    "\n",
    "- `model` (PyTorch module): The defined scPROTEIN *stage2* model.\n",
    "\n",
    "\n",
    "\n",
    "<br/>\n",
    "\n",
    "\n",
    "\n",
    "**scPROTEIN_learning(model, device, data, drop_feature_rate_1, drop_feature_rate_2, drop_edge_rate_1, drop_edge_rate_2, learning_rate, weight_decay, num_protos, topology_denoising, num_epochs, alpha, num_changed_edges, seed)**\n",
    "\n",
    "**- Function:**\n",
    "\n",
    "This function constructs the framework of scPROTEIN *stage2* training and prediction.\n",
    "\n",
    "**- Parameters:**\n",
    "\n",
    "- `model` (PyTorch module): Defined scPROTEIN *stage2* model.\n",
    "- `device` (str): Running device.\n",
    "- `data` (torch_geometric data): The defined graph data in torch_geometric format, consisting of edges and node features.\n",
    "- `drop_feature_rate_1` (float): Dropedge rate for augmentation view1.\n",
    "- `drop_feature_rate_2` (float): Dropedge rate for augmentation view2.\n",
    "- `drop_edge_rate_1` (float): Feature masking rate for augmentation view1.\n",
    "- `drop_edge_rate_2` (float): Feature masking rate for augmentation view2.\n",
    "- `learning_rate` (float): Learning rate for Adam optimizer.\n",
    "- `weight_decay` (float): Weight decay for Adam optimizer.\n",
    "- `num_protos` (int): Number of prototypes.\n",
    "- `topology_denoising` (bool): Indicator of if using the topology denoising.\n",
    "- `num_epochs` (int): Number of epochs for training *stage2*. We empirically set 200 to strike a balance between achieving convergence and reducing training time.\n",
    "- `alpha` (float): Balance factor in the loss function.\n",
    "- `num_changed_edges` (int): Number of added/removed edges in topology denoising.\n",
    "- `seed` (int): Random seed.\n",
    "\n",
    "**- Returns:**\n",
    "\n",
    "- `scPROTEIN` object for *stage2*. The functions of `scPROTEIN` are as follows:\n",
    "\n",
    "    - `scPROTEIN.train()`: Conduct training of scPROTEIN *stage2*.\n",
    "    - `scPROTEIN.embedding_generation()`: Generate the cell representation matrix based on the trained *stage2* model.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "24d36ea9",
   "metadata": {},
   "outputs": [],
   "source": [
    "protein_list, cell_list, features = load_sc_proteomic_features(args.stage1)  \n",
    "device = torch.device('cuda:0' if torch.cuda.is_available() else 'cpu')\n",
    "data = graph_generation(features, args.threshold, args.feature_preprocess).to(device)\n",
    "torch.cuda.empty_cache()\n",
    "encoder = Encoder(data.num_features, args.num_hidden, activation, k=args.num_layers).to(device)\n",
    "model = Model(encoder, args.num_hidden, args.num_proj_hidden, args.tau).to(device)\n",
    "scPROTEIN = scPROTEIN_learning(model,device, data, args.drop_feature_rate_1,args.drop_feature_rate_2,args.drop_edge_rate_1,args.drop_edge_rate_2,\n",
    "                 args.learning_rate, args.weight_decay, args.num_protos, args.topology_denoising, args.num_epochs, args.alpha, args.num_changed_edges,args.seed)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c07b1ec3",
   "metadata": {},
   "source": [
    "### Model training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "49f14ef5",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(T) | Epoch=001, loss=8.0031 \n",
      "(T) | Epoch=002, loss=7.6771 \n",
      "(T) | Epoch=003, loss=7.3166 \n",
      "(T) | Epoch=004, loss=7.2599 \n",
      "(T) | Epoch=005, loss=7.2623 \n",
      "(T) | Epoch=006, loss=7.2776 \n",
      "(T) | Epoch=007, loss=7.2702 \n",
      "(T) | Epoch=008, loss=7.2547 \n",
      "(T) | Epoch=009, loss=7.2358 \n",
      "(T) | Epoch=010, loss=7.2018 \n",
      "(T) | Epoch=011, loss=7.1948 \n",
      "(T) | Epoch=012, loss=7.1154 \n",
      "(T) | Epoch=013, loss=7.0538 \n",
      "(T) | Epoch=014, loss=6.9621 \n",
      "(T) | Epoch=015, loss=6.9185 \n",
      "(T) | Epoch=016, loss=6.8925 \n",
      "(T) | Epoch=017, loss=6.8923 \n",
      "(T) | Epoch=018, loss=6.8674 \n",
      "(T) | Epoch=019, loss=6.9867 \n",
      "(T) | Epoch=020, loss=6.9094 \n",
      "(T) | Epoch=021, loss=6.8531 \n",
      "(T) | Epoch=022, loss=6.9533 \n",
      "(T) | Epoch=023, loss=6.9475 \n",
      "(T) | Epoch=024, loss=6.8666 \n",
      "(T) | Epoch=025, loss=6.8541 \n",
      "(T) | Epoch=026, loss=6.8498 \n",
      "(T) | Epoch=027, loss=6.9048 \n",
      "(T) | Epoch=028, loss=6.7885 \n",
      "(T) | Epoch=029, loss=6.8036 \n",
      "(T) | Epoch=030, loss=6.7530 \n",
      "(T) | Epoch=031, loss=6.8465 \n",
      "(T) | Epoch=032, loss=7.0136 \n",
      "(T) | Epoch=033, loss=6.7679 \n",
      "(T) | Epoch=034, loss=6.7590 \n",
      "(T) | Epoch=035, loss=6.7734 \n",
      "(T) | Epoch=036, loss=6.8029 \n",
      "(T) | Epoch=037, loss=6.7484 \n",
      "(T) | Epoch=038, loss=6.7398 \n",
      "(T) | Epoch=039, loss=6.7567 \n",
      "(T) | Epoch=040, loss=6.7334 \n",
      "(T) | Epoch=041, loss=6.6962 \n",
      "(T) | Epoch=042, loss=6.6942 \n",
      "(T) | Epoch=043, loss=6.7762 \n",
      "(T) | Epoch=044, loss=6.6753 \n",
      "(T) | Epoch=045, loss=6.7573 \n",
      "(T) | Epoch=046, loss=6.7163 \n",
      "(T) | Epoch=047, loss=6.7260 \n",
      "(T) | Epoch=048, loss=6.6300 \n",
      "(T) | Epoch=049, loss=6.7704 \n",
      "(T) | Epoch=050, loss=6.7736 \n",
      "(T) | Epoch=051, loss=6.6735 \n",
      "(T) | Epoch=052, loss=6.6691 \n",
      "(T) | Epoch=053, loss=6.6765 \n",
      "(T) | Epoch=054, loss=6.6384 \n",
      "(T) | Epoch=055, loss=6.6984 \n",
      "(T) | Epoch=056, loss=6.7130 \n",
      "(T) | Epoch=057, loss=6.6548 \n",
      "(T) | Epoch=058, loss=6.6648 \n",
      "(T) | Epoch=059, loss=6.6236 \n",
      "(T) | Epoch=060, loss=6.6147 \n",
      "(T) | Epoch=061, loss=6.6785 \n",
      "(T) | Epoch=062, loss=6.6946 \n",
      "(T) | Epoch=063, loss=6.6093 \n",
      "(T) | Epoch=064, loss=6.6009 \n",
      "(T) | Epoch=065, loss=6.6917 \n",
      "(T) | Epoch=066, loss=6.6607 \n",
      "(T) | Epoch=067, loss=6.6545 \n",
      "(T) | Epoch=068, loss=6.6538 \n",
      "(T) | Epoch=069, loss=6.6813 \n",
      "(T) | Epoch=070, loss=6.6313 \n",
      "(T) | Epoch=071, loss=6.6295 \n",
      "(T) | Epoch=072, loss=6.6355 \n",
      "(T) | Epoch=073, loss=6.6481 \n",
      "(T) | Epoch=074, loss=6.6188 \n",
      "(T) | Epoch=075, loss=6.6050 \n",
      "(T) | Epoch=076, loss=6.6381 \n",
      "(T) | Epoch=077, loss=6.5943 \n",
      "(T) | Epoch=078, loss=6.6471 \n",
      "(T) | Epoch=079, loss=7.0342 \n",
      "(T) | Epoch=080, loss=6.6472 \n",
      "(T) | Epoch=081, loss=6.6403 \n",
      "(T) | Epoch=082, loss=6.6234 \n",
      "(T) | Epoch=083, loss=6.6480 \n",
      "(T) | Epoch=084, loss=6.6372 \n",
      "(T) | Epoch=085, loss=6.6340 \n",
      "(T) | Epoch=086, loss=6.6225 \n",
      "(T) | Epoch=087, loss=6.6633 \n",
      "(T) | Epoch=088, loss=6.6371 \n",
      "(T) | Epoch=089, loss=6.6092 \n",
      "(T) | Epoch=090, loss=6.6213 \n",
      "(T) | Epoch=091, loss=6.6029 \n",
      "(T) | Epoch=092, loss=6.5388 \n",
      "(T) | Epoch=093, loss=6.5334 \n",
      "(T) | Epoch=094, loss=6.5150 \n",
      "(T) | Epoch=095, loss=6.5255 \n",
      "(T) | Epoch=096, loss=6.6193 \n",
      "(T) | Epoch=097, loss=6.4615 \n",
      "(T) | Epoch=098, loss=6.4846 \n",
      "(T) | Epoch=099, loss=6.4865 \n",
      "(T) | Epoch=100, loss=6.7044 \n",
      "(T) | Epoch=101, loss=6.4776 \n",
      "(T) | Epoch=102, loss=6.5645 \n",
      "(T) | Epoch=103, loss=6.5057 \n",
      "(T) | Epoch=104, loss=6.6374 \n",
      "(T) | Epoch=105, loss=6.5188 \n",
      "(T) | Epoch=106, loss=6.5315 \n",
      "(T) | Epoch=107, loss=6.4747 \n",
      "(T) | Epoch=108, loss=6.5367 \n",
      "(T) | Epoch=109, loss=6.4975 \n",
      "(T) | Epoch=110, loss=6.5753 \n",
      "(T) | Epoch=111, loss=6.5291 \n",
      "(T) | Epoch=112, loss=6.4599 \n",
      "(T) | Epoch=113, loss=6.5136 \n",
      "(T) | Epoch=114, loss=6.4975 \n",
      "(T) | Epoch=115, loss=6.5356 \n",
      "(T) | Epoch=116, loss=6.5540 \n",
      "(T) | Epoch=117, loss=6.5530 \n",
      "(T) | Epoch=118, loss=6.5049 \n",
      "(T) | Epoch=119, loss=6.4595 \n",
      "(T) | Epoch=120, loss=6.5057 \n",
      "(T) | Epoch=121, loss=6.4624 \n",
      "(T) | Epoch=122, loss=6.4614 \n",
      "(T) | Epoch=123, loss=6.5950 \n",
      "(T) | Epoch=124, loss=6.4726 \n",
      "(T) | Epoch=125, loss=6.4950 \n",
      "(T) | Epoch=126, loss=6.4711 \n",
      "(T) | Epoch=127, loss=6.4434 \n",
      "(T) | Epoch=128, loss=6.5000 \n",
      "(T) | Epoch=129, loss=6.4664 \n",
      "(T) | Epoch=130, loss=6.4734 \n",
      "(T) | Epoch=131, loss=6.6192 \n",
      "(T) | Epoch=132, loss=6.4782 \n",
      "(T) | Epoch=133, loss=6.4625 \n",
      "(T) | Epoch=134, loss=6.4347 \n",
      "(T) | Epoch=135, loss=6.5199 \n",
      "(T) | Epoch=136, loss=6.4720 \n",
      "(T) | Epoch=137, loss=6.4348 \n",
      "(T) | Epoch=138, loss=6.4430 \n",
      "(T) | Epoch=139, loss=6.5053 \n",
      "(T) | Epoch=140, loss=6.4311 \n",
      "(T) | Epoch=141, loss=6.4528 \n",
      "(T) | Epoch=142, loss=6.5515 \n",
      "(T) | Epoch=143, loss=6.4061 \n",
      "(T) | Epoch=144, loss=6.5024 \n",
      "(T) | Epoch=145, loss=6.4037 \n",
      "(T) | Epoch=146, loss=6.4254 \n",
      "(T) | Epoch=147, loss=6.4689 \n",
      "(T) | Epoch=148, loss=6.4443 \n",
      "(T) | Epoch=149, loss=6.4037 \n",
      "(T) | Epoch=150, loss=6.4147 \n",
      "(T) | Epoch=151, loss=6.4255 \n",
      "(T) | Epoch=152, loss=6.4457 \n",
      "(T) | Epoch=153, loss=6.3794 \n",
      "(T) | Epoch=154, loss=6.3929 \n",
      "(T) | Epoch=155, loss=6.3905 \n",
      "(T) | Epoch=156, loss=6.4868 \n",
      "(T) | Epoch=157, loss=6.4607 \n",
      "(T) | Epoch=158, loss=6.3929 \n",
      "(T) | Epoch=159, loss=6.4191 \n",
      "(T) | Epoch=160, loss=6.3993 \n",
      "(T) | Epoch=161, loss=6.4094 \n",
      "(T) | Epoch=162, loss=6.4357 \n",
      "(T) | Epoch=163, loss=6.3916 \n",
      "(T) | Epoch=164, loss=6.4196 \n",
      "(T) | Epoch=165, loss=6.4052 \n",
      "(T) | Epoch=166, loss=6.3935 \n",
      "(T) | Epoch=167, loss=6.4292 \n",
      "(T) | Epoch=168, loss=6.3963 \n",
      "(T) | Epoch=169, loss=6.4828 \n",
      "(T) | Epoch=170, loss=6.4470 \n",
      "(T) | Epoch=171, loss=6.4053 \n",
      "(T) | Epoch=172, loss=6.4464 \n",
      "(T) | Epoch=173, loss=6.4406 \n",
      "(T) | Epoch=174, loss=6.4122 \n",
      "(T) | Epoch=175, loss=6.4351 \n",
      "(T) | Epoch=176, loss=6.3848 \n",
      "(T) | Epoch=177, loss=6.4037 \n",
      "(T) | Epoch=178, loss=6.4271 \n",
      "(T) | Epoch=179, loss=6.4403 \n",
      "(T) | Epoch=180, loss=6.3833 \n",
      "(T) | Epoch=181, loss=6.3712 \n",
      "(T) | Epoch=182, loss=6.4796 \n",
      "(T) | Epoch=183, loss=6.3803 \n",
      "(T) | Epoch=184, loss=6.4597 \n",
      "(T) | Epoch=185, loss=6.3839 \n",
      "(T) | Epoch=186, loss=6.4199 \n",
      "(T) | Epoch=187, loss=6.4174 \n",
      "(T) | Epoch=188, loss=6.4825 \n",
      "(T) | Epoch=189, loss=6.3983 \n",
      "(T) | Epoch=190, loss=6.3898 \n",
      "(T) | Epoch=191, loss=6.3827 \n",
      "(T) | Epoch=192, loss=6.4193 \n",
      "(T) | Epoch=193, loss=6.4259 \n",
      "(T) | Epoch=194, loss=6.4199 \n",
      "(T) | Epoch=195, loss=6.3675 \n",
      "(T) | Epoch=196, loss=6.3672 \n",
      "(T) | Epoch=197, loss=6.3629 \n",
      "(T) | Epoch=198, loss=6.3914 \n",
      "(T) | Epoch=199, loss=6.4007 \n",
      "(T) | Epoch=200, loss=6.3870 \n"
     ]
    }
   ],
   "source": [
    "scPROTEIN.train()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cceea039",
   "metadata": {},
   "source": [
    "### Generate the cell embedding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "cab32e2d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1490, 400)"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "embedding = scPROTEIN.embedding_generation()\n",
    "embedding.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8c4b8fd2",
   "metadata": {},
   "source": [
    "### Evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "4d57aa70",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cell clustering result:\n",
      "     ARI    ASW    NMI     PS\n",
      "0  0.435  0.469  0.428  0.831\n"
     ]
    }
   ],
   "source": [
    "def purity_score(y_true, y_pred):\n",
    "    contingency_matrix1 = contingency_matrix(y_true, y_pred)\n",
    "    return np.sum(np.amax(contingency_matrix1, axis=0)) / np.sum(contingency_matrix1) \n",
    "\n",
    "\n",
    "def dimension_reduce(embedding):\n",
    "    X_trans_PCA = PCA(n_components=50, random_state=seed).fit_transform(embedding)  \n",
    "    X_trans = TSNE(n_components=2,random_state=seed).fit_transform(X_trans_PCA)\n",
    "    return X_trans\n",
    "\n",
    "seed = 1\n",
    "Y_cell_type_label = load_cell_type_labels()\n",
    "label_dict = {'sc_m0':0, 'sc_u':1}\n",
    "target_names = ['Macrophage','Monocyte']\n",
    "Y_label = np.array(itemgetter(*list(Y_cell_type_label))(label_dict))\n",
    "\n",
    "k_means = KMeans(n_clusters=len(target_names))\n",
    "y_predict = k_means.fit_predict(embedding)\n",
    "df_result = pd.DataFrame()\n",
    "df_result['ARI'] = [np.round(adjusted_rand_score(Y_label,y_predict),3)]\n",
    "df_result['ASW'] = [np.round(silhouette_score(embedding,y_predict),3)]\n",
    "df_result['NMI'] = [np.round(normalized_mutual_info_score(Y_label,y_predict),3)]\n",
    "df_result['PS'] = [np.round(purity_score(Y_label,y_predict),3)]\n",
    "print('cell clustering result:')\n",
    "print(df_result)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
